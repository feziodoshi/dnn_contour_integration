{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1,'../')\n",
    "sys.path.insert(1,'../models/')\n",
    "\n",
    "\n",
    "# Pytorch related\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils import data as dt\n",
    "from torchinfo import summary\n",
    "import torchvision.models as pretrained_models\n",
    "from alexnet_pytorch import AlexNet\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils import model_zoo\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Extra imports\n",
    "# from pytorch_pretrained_vit import ViT\n",
    "from lib.feature_extractor import FeatureExtractor\n",
    "from lib.build_fe_ft_models import *\n",
    "from models import barlow_twins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_device='0'\n",
    "device = torch.device('cuda:'+use_device if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This can be either madgrad; onecyle\n",
    "# training_config={'training_type':'feature_extractor','base_model_name':'sup_regular','layer_name':'features.4',\n",
    "#                  'optimizer_name':'sgd','optimizer_lr':0.001,'optimizer_scheduler':True,'optimizer_wd':0.0,'total_num_epochs':100}\n",
    "\n",
    "# training_config={'training_type':'feature_extractor','base_model_name':'sup_stylized','layer_name':'features.4',\n",
    "#                  'optimizer_name':'sgd','optimizer_lr':0.001,'optimizer_scheduler':True,'optimizer_wd':0.0,'total_num_epochs':100}\n",
    "\n",
    "\n",
    "# training_config={'training_type':'feature_extractor','base_model_name':'unsup_barlow','layer_name':'backbone.5',\n",
    "#                  'optimizer_name':'sgd','optimizer_lr':0.001,'optimizer_scheduler':True,'optimizer_wd':0.0,'total_num_epochs':100}\n",
    "\n",
    "\n",
    "# training_config={'training_type':'feature_extractor','base_model_name':'vit_regular','layer_name':'transformer.blocks.1.attn',\n",
    "#                  'optimizer_name':'sgd','optimizer_lr':0.001,'optimizer_scheduler':True,'optimizer_wd':0.0,'total_num_epochs':100}\n",
    "\n",
    "\n",
    "training_config={'training_type':'feature_extractor','base_model_name':'alexnet_bagnet9','layer_name':'features.4',\n",
    "                 'optimizer_name':'sgd','optimizer_lr':0.001,'optimizer_scheduler':True,'optimizer_wd':0.0,'total_num_epochs':100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name=training_config['base_model_name']\n",
    "layer_name=training_config['layer_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splice Model Class - added in the python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SpliceModel(nn.Module):\n",
    "#     def __init__(self, base_model_name, layer_name,fine_tune=True, device='cpu'):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.base_model_name=base_model_name\n",
    "#         self.layer_name=layer_name\n",
    "#         self.fine_tune=fine_tune\n",
    "#         self.device=device\n",
    "#         self.temp_input_to_base=None\n",
    "        \n",
    "        \n",
    "#         self.base_model=get_base_model(self.base_model_name).to(self.device)\n",
    "#         self.arrange_base_model()\n",
    "        \n",
    "        \n",
    "#         self.readout_model=get_readout_model(self.base_model,self.layer_name,temp_input_to_base=self.temp_input_to_base).to(self.device)\n",
    "        \n",
    "        \n",
    "    \n",
    "#     def arrange_base_model(self):\n",
    "#         if(self.fine_tune):\n",
    "#             ## Do nothing\n",
    "#             pass\n",
    "#         else:\n",
    "#             ##freeze the weights of self.base model\n",
    "#             freeze_all_parameters(self.base_model)\n",
    "#             self.base_model.eval()\n",
    "        \n",
    "        \n",
    "#         if('vit' not in self.base_model_name):\n",
    "#             self.temp_input_to_base=torch.randn(2,3,512,512).to(self.device)\n",
    "\n",
    "#         else:\n",
    "#             self.temp_input_to_base=torch.randn(2,3,384,384).to(self.device)\n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         output=None\n",
    "#         with FeatureExtractor(self.base_model, self.layer_name, detach=False, clone=True, retain=False) as extractor:\n",
    "\n",
    "#             features = extractor(x)\n",
    "#             temp_input_to_readout=features[self.layer_name].to(self.device)\n",
    "#             if(len(temp_input_to_readout.shape)!=2):\n",
    "#                 temp_input_to_readout=temp_input_to_readout.view((temp_input_to_readout.shape[0],-1))\n",
    "\n",
    "#             output= self.readout_model(temp_input_to_readout)\n",
    "#         return output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to get only trainable parameters - added in the python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_untrainable_params(spliced_model):\n",
    "    \n",
    "#     assert isinstance(spliced_model,SpliceModel)\n",
    "#     list_untrainable_parameters=[]\n",
    "#     torch.mean(spliced_model.forward(spliced_model.temp_input_to_base)).backward()\n",
    "\n",
    "#     for name,param in spliced_model.named_parameters():\n",
    "#         if(param.requires_grad==False):\n",
    "#             # All the frozen parameters\n",
    "#             list_untrainable_parameters.append(name)\n",
    "#         else:\n",
    "#             ## This is for the fine-tune model parameters which are after the hooked layer so, not frozen by default but are unused and not updated\n",
    "#             if(param.grad==None):\n",
    "#                 list_untrainable_parameters.append(name)\n",
    "    \n",
    "#     return list_untrainable_parameters\n",
    "\n",
    "\n",
    "# def get_modified_state_dict(spliced_model,list_untrainable_parameters):\n",
    "#     temp_dict=spliced_model.state_dict()\n",
    "#     for key in list_untrainable_parameters:\n",
    "#         del temp_dict[key]\n",
    "#     return temp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading checkpoint: ../../dev/base_model_weights/alexnet_bagnet9_73111_final_weights_pytorch2-26c23b5440.pth\n"
     ]
    }
   ],
   "source": [
    "spliced_model=SpliceModel(base_model_name,layer_name,fine_tune=fine_tune,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpliceModel(\n",
       "  (base_model): AlexNetBagnet9_73111(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (9): ReLU(inplace=True)\n",
       "    )\n",
       "    (avgpool): Sequential(\n",
       "      (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (pool2): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (readout_model): Sequential(\n",
       "    (0): Linear(in_features=97542144, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spliced_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Checking the parameters - Updated params, Saved params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_all_parameters=[]\n",
    "names_all_parameters_requires_grad=[]\n",
    "for name,param in spliced_model.named_parameters():\n",
    "    names_all_parameters.append(name)\n",
    "    if(param.requires_grad):\n",
    "        names_all_parameters_requires_grad.append(name)\n",
    "\n",
    "\n",
    "keys_all_state_dict=list(spliced_model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(names_all_parameters)\n",
    "\n",
    "print(names_all_parameters_requires_grad)\n",
    "\n",
    "print(keys_all_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_img=torch.randn(2,3,512,512).to(device)\n",
    "\n",
    "# view_img=torch.randn(2,3,384,384).to(device)\n",
    "\n",
    "\n",
    "spliced_model.forward(view_img).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. The following cells need to be run sequenctially to check if gradients get saved or not, Skip this and go to 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4A. Get input to the spliced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_img=torch.randn(2,3,512,512).to(device)\n",
    "\n",
    "# view_img=torch.randn(2,3,384,384).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4B. Check if gradients are saved yet, if just constructed, it shouldn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(spliced_model.base_model.parameters())[0].grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(spliced_model.readout_model.parameters())[0].grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(spliced_model.parameters())[0].grad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Get the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=spliced_model.forward(view_img)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4D. Check again if gradients are saved yet. Since errors are not propagated back, it shouldn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(spliced_model.base_model.parameters())[0].grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(spliced_model.readout_model.parameters())[0].grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(spliced_model.parameters())[0].grad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4E. Get loss and propagate the errors back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.MSELoss()\n",
    "target=torch.randn_like(output)\n",
    "loss=criterion(target,output)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "\n",
    "\n",
    "# torch.mean(output).backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4F. Check again if gradients are saved yet. Finally, errors have been propagated back, so should be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(spliced_model.base_model.parameters())[0].grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(spliced_model.readout_model.parameters())[0].grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(spliced_model.parameters())[0].grad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving all the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'model_state_dict':spliced_model.state_dict},'./model.pt')\n",
    "!ls -lh ./model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving only the trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_modified_state_dict(spliced_model,get_untrainable_params(spliced_model)).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'base_model_name':base_model_name,\n",
    "            'layer_name':layer_name,\n",
    "            'fine_tune':True,\n",
    "            'device':device,\n",
    "            'model_state_dict':get_modified_state_dict(spliced_model,get_untrainable_params(spliced_model))},'./model.pt')\n",
    "!ls -lh ./model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint=torch.load('./model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_spliced_model=SpliceModel(checkpoint['base_model_name'],checkpoint['layer_name'],fine_tune=checkpoint['fine_tune'],device=checkpoint['device'])\n",
    "loaded_spliced_model.load_state_dict(checkpoint['model_state_dict'],strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Outputs from the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_img=torch.randn(2,3,512,512).to(checkpoint['device'])\n",
    "\n",
    "loaded_spliced_model.forward(view_img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_spliced_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Swicthing model eval and train models [Function added to py file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spliced_model.training)\n",
    "\n",
    "print(spliced_model.base_model.training)\n",
    "\n",
    "print(spliced_model.readout_model.training)\n",
    "\n",
    "print(fine_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def change_train_eval_mode(spliced_model,fine_tune,train_eval_mode='eval'):\n",
    "#     if(fine_tune):\n",
    "#         if(train_eval_mode=='train'):\n",
    "#             spliced_model.train()\n",
    "#         elif(train_eval_mode=='eval'):\n",
    "#             spliced_model.eval()\n",
    "#     else:\n",
    "#         if(train_eval_mode=='train'):\n",
    "#             spliced_model.train()\n",
    "#             spliced_model.base_model.eval()\n",
    "#             # This is just for safety check, already true because whole sploiced model is in training mode\n",
    "#             spliced_model.readout_model.train()\n",
    "#         elif(train_eval_mode=='eval'):\n",
    "#             spliced_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_train_eval_mode(spliced_model,False,train_eval_mode='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spliced_model.training)\n",
    "\n",
    "print(spliced_model.base_model.training)\n",
    "\n",
    "print(spliced_model.readout_model.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
