{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.insert(1,'../')\n",
    "\n",
    "# Import python library for this notebook\n",
    "import numpy as np # fundamental package for scientific computing\n",
    "import matplotlib.pyplot as plt # package for plot function\n",
    "import math\n",
    "import torch\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "from IPython.html.widgets import interact, interactive, fixed\n",
    "from IPython.display import display \n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import copy\n",
    "\n",
    "# show figures inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Extra imports\n",
    "from field_stim_functions import *\n",
    "from training_psychophysics_config import *\n",
    "\n",
    "# Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters\n",
    "\n",
    "* imported from the training_psychophysics_config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experiment_dir': '/home/jovyan/work/Datasets/contour_integration/model-training/config_0', 'num_images_train': 2500, 'num_images_val': 50, 'num_elements_list': [12], 'alpha_list': [0], 'beta_list': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
      "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
      "       85, 86, 87, 88, 89, 90]), 'D_list': [32.0], 'jitterB': 10, 'jitterD': 0.25, 'gridSize': (16, 16), 'imWidth': 512, 'imHeight': 512, 'startRadius': 64, 'gabor_lambda': 8, 'gabor_phase': -90, 'gabor_stddev': 4.0, 'gabor_imSize': 28, 'gabor_elCentre': None, 'gabor_gratingContrast': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(model_training_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folders(path):\n",
    "    if(not os.path.exists(path)):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    return path\n",
    "\n",
    "def append_values_dict(original_dict,append_dict):\n",
    "    for key in append_dict.keys():\n",
    "        original_dict[key].append(append_dict[key])\n",
    "    return original_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to generate model-training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_data(experiment):\n",
    "\n",
    "    _=make_folders(experiment['experiment_dir'])\n",
    "    ## Save the complete config file for the given experiment\n",
    "    torch.save(experiment,os.path.join(experiment['experiment_dir'],'experiment_config.pth'))\n",
    "    \n",
    "    ## Training, Validation, Psychophysics folders for data\n",
    "    folder_train_img=make_folders(os.path.join(experiment['experiment_dir'],'train_img'))\n",
    "    folder_val_img=make_folders(os.path.join(experiment['experiment_dir'],'val_img'))\n",
    "    \n",
    "    ## Training, Validation folders for configs - imagerecorders\n",
    "    folder_train_config = make_folders(os.path.join(experiment['experiment_dir'],'train_recorder'))\n",
    "    folder_val_config = make_folders(os.path.join(experiment['experiment_dir'],'val_recorder'))\n",
    "    \n",
    "    ## Total number of images for train, val, psychophysics\n",
    "    total_images_train=len(experiment['beta_list']) * len(experiment['alpha_list']) * len(experiment['num_elements_list']) * len(experiment['D_list']) * experiment['num_images_train']\n",
    "    total_images_val=len(experiment['beta_list']) * len(experiment['alpha_list']) * len(experiment['num_elements_list']) * len(experiment['D_list']) * experiment['num_images_val']\n",
    "\n",
    "    ## CSV File for the training, validation, and the psychophysics code\n",
    "    csv_train={'img_path':[],'D':[], 'B':[], 'A':[],'numElements':[],'c':[],'img_recorder_path':[],'id_num':[]}\n",
    "    csv_val={'img_path':[],'D':[], 'B':[], 'A':[],'numElements':[],'c':[],'img_recorder_path':[],'id_num':[]}\n",
    "    \n",
    "    ###########################################################################################################################################################\n",
    "    # Generating the images for TRAIN\n",
    "    id_num=0\n",
    "    for beta in tqdm(experiment['beta_list']):\n",
    "        for alpha in tqdm(experiment['alpha_list'],disable=True):\n",
    "            for num_elements in tqdm(experiment['num_elements_list'],disable=True):\n",
    "                for D in tqdm(experiment['D_list'],disable=True):\n",
    "                    \n",
    "                    \n",
    "                    for i in range(experiment['num_images_train']):\n",
    "                        img_id=str(id_num).zfill(len(str(total_images_train)))\n",
    "\n",
    "                        img_contour, img_control, img_contour_background, img_control_background, points, centers, grid, image_recorder_dict= generate_everything(imWidth=experiment['imWidth'], imHeight=experiment['imHeight'],\n",
    "                                                                                                                                                                  numElements=num_elements,D=D, jitterD=experiment['jitterD'], B=beta, jitterB=experiment['jitterB'], \n",
    "                                                                                                                                                                  startRadius=experiment['startRadius'], alpha_offset=90-alpha,gridSize=experiment['gridSize'],\n",
    "                                                                                                                                                                  max_attempts=100,\n",
    "                                                                                                                                                                  gabor_lambda=experiment['gabor_lambda'],gabor_phase=experiment['gabor_phase'],gabor_stddev=experiment['gabor_stddev'],gabor_imSize=experiment['gabor_imSize'],gabor_elCentre=experiment['gabor_elCentre'],gabor_gratingContrast=experiment['gabor_gratingContrast'])\n",
    "\n",
    "                        # recorder path            \n",
    "                        image_recorder_path= os.path.join(folder_train_config,'train_recorder_id' + img_id + '.pth')\n",
    "                        torch.save(image_recorder_dict,image_recorder_path)\n",
    "\n",
    "                        # recorder dictionary for contour_bg1\n",
    "                        img_contour_background_name = 'train_D' + str(D) + '_B' + str(beta) + '_A' + str(alpha) + '_Numel' + str(num_elements) + '_contour_id' + img_id + '.png'\n",
    "                        img_contour_background_path=os.path.join(folder_train_img,img_contour_background_name)\n",
    "                        csv_train=append_values_dict(csv_train,{'D':D,'B':beta,'A':alpha,'numElements':num_elements,'c':'contour','img_path':img_contour_background_path,'img_recorder_path':image_recorder_path,'id_num':img_id})\n",
    "                        img_contour_background.save(img_contour_background_path)\n",
    "\n",
    "\n",
    "                        # recorder dictionary for nocontour_bg1\n",
    "                        img_control_background_name = 'train_D' + str(D) + '_B' + str(beta) + '_A' + str(alpha) + '_Numel' + str(num_elements) + '_control_id' + img_id+ '.png'\n",
    "                        img_control_background_path=os.path.join(folder_train_img,img_control_background_name)\n",
    "                        csv_train=append_values_dict(csv_train,{'D':D,'B':beta,'A':alpha,'numElements':num_elements,'c':'control','img_path':img_control_background_path,'img_recorder_path':image_recorder_path,'id_num':img_id})\n",
    "                        img_control_background.save(img_control_background_path)\n",
    "\n",
    "\n",
    "                        id_num+=1\n",
    "\n",
    "    print('Completed version: train \\t with id num:',id_num)\n",
    "    ###########################################################################################################################################################\n",
    "    \n",
    "    \n",
    "    ###########################################################################################################################################################\n",
    "    # Generating the images for VAL\n",
    "    id_num=0\n",
    "    for beta in tqdm(experiment['beta_list']):\n",
    "        for alpha in tqdm(experiment['alpha_list'],disable=True):\n",
    "            for num_elements in tqdm(experiment['num_elements_list'],disable=True):\n",
    "                for D in tqdm(experiment['D_list'],disable=True):\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    for i in range(experiment['num_images_val']):\n",
    "                        img_id=str(id_num).zfill(len(str(total_images_val)))\n",
    "\n",
    "                        img_contour, img_control, img_contour_background, img_control_background, points, centers, grid, image_recorder_dict= generate_everything(imWidth=experiment['imWidth'], imHeight=experiment['imHeight'],\n",
    "                                                                                                                                                                  numElements=num_elements,D=D, jitterD=experiment['jitterD'], B=beta, jitterB=experiment['jitterB'], \n",
    "                                                                                                                                                                  startRadius=experiment['startRadius'], alpha_offset=90-alpha,gridSize=experiment['gridSize'],\n",
    "                                                                                                                                                                  max_attempts=100,\n",
    "                                                                                                                                                                  gabor_lambda=experiment['gabor_lambda'],gabor_phase=experiment['gabor_phase'],gabor_stddev=experiment['gabor_stddev'],gabor_imSize=experiment['gabor_imSize'],gabor_elCentre=experiment['gabor_elCentre'],gabor_gratingContrast=experiment['gabor_gratingContrast'])\n",
    "\n",
    "                        # recorder path            \n",
    "                        image_recorder_path= os.path.join(folder_val_config,'val_recorder_id' + img_id + '.pth')\n",
    "                        torch.save(image_recorder_dict,image_recorder_path)\n",
    "\n",
    "                        # recorder dictionary for contour_bg1\n",
    "                        img_contour_background_name = 'val_D' + str(D) + '_B' + str(beta) + '_A' + str(alpha) + '_Numel' + str(num_elements) + '_contour_id' + img_id + '.png'\n",
    "                        img_contour_background_path=os.path.join(folder_val_img,img_contour_background_name)\n",
    "                        csv_val=append_values_dict(csv_val,{'D':D,'B':beta,'A':alpha, 'numElements':num_elements,'c':'contour','img_path':img_contour_background_path,'img_recorder_path':image_recorder_path,'id_num':img_id})\n",
    "                        img_contour_background.save(img_contour_background_path)\n",
    "\n",
    "\n",
    "                        # recorder dictionary for nocontour_bg1\n",
    "                        img_control_background_name = 'val_D' + str(D) + '_B' + str(beta) + '_A' + str(alpha) + '_Numel' + str(num_elements) + '_control_id' + img_id+ '.png'\n",
    "                        img_control_background_path=os.path.join(folder_val_img,img_control_background_name)\n",
    "                        csv_val=append_values_dict(csv_val,{'D':D,'B':beta,'A':alpha, 'numElements':num_elements,'c':'control','img_path':img_control_background_path,'img_recorder_path':image_recorder_path,'id_num':img_id})\n",
    "                        img_control_background.save(img_control_background_path)\n",
    "\n",
    "\n",
    "                        id_num+=1\n",
    "\n",
    "    print('Completed version: val \\t with id num:',id_num)\n",
    "    ###########################################################################################################################################################\n",
    "    \n",
    "    pd.DataFrame(csv_train).to_csv(os.path.join(experiment['experiment_dir'],'train.csv'),index=False)\n",
    "    pd.DataFrame(csv_val).to_csv(os.path.join(experiment['experiment_dir'],'val.csv'),index=False)\n",
    "    return pd.DataFrame(csv_train),pd.DataFrame(csv_val)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function(s) to generate model-psychophysics/model-generalization data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_recorder_json(recorder_dict,filename='001.pth'):\n",
    "    \n",
    "    trial_element_dict={key: None for key in ['filename', 'image_params', 'contour_params', 'element_params', 'elements']}\n",
    "    trial_element_dict['filename']=filename\n",
    "\n",
    "    trial_element_dict['image_params']={'grid_size':[recorder_dict['grid'].shape[0],recorder_dict['grid'].shape[1]],\n",
    "                                       'imSize':[recorder_dict['image_width'],recorder_dict['image_height']]}\n",
    "\n",
    "    trial_element_dict['contour_params']={'B':recorder_dict['path_B'],\n",
    "                                          'D':recorder_dict['path_D'],\n",
    "                                          'A':recorder_dict['path_A'],\n",
    "                                          'numElements':recorder_dict['path_numElement'],\n",
    "                                          'jitterB':recorder_dict['path_jitterB'],\n",
    "                                          'jitterD':recorder_dict['path_jitterD']}\n",
    "\n",
    "    trial_element_dict['element_params']={'bg_contrast': recorder_dict['gabor_gratingContrast'],\n",
    "                                         'path_contrast': recorder_dict['gabor_gratingContrast'],\n",
    "                                         'period': recorder_dict['gabor_lambda'],\n",
    "                                         'phase': recorder_dict['gabor_phase'],\n",
    "                                         'rand_phase': False,\n",
    "                                         'rand_target_angle': False,\n",
    "                                         'sigma': recorder_dict['gabor_stdev'],\n",
    "                                         'size': recorder_dict['gabor_imSize']}\n",
    "\n",
    "    all_list_elements=[]\n",
    "    for row in range(recorder_dict['grid'].shape[0]):\n",
    "        row_wise_list_elements=[]\n",
    "        for col in range(recorder_dict['grid'].shape[1]):\n",
    "            element_dict={}\n",
    "            element_dict['row']=row\n",
    "            element_dict['col']=col\n",
    "\n",
    "            x_pos,y_pos=recorder_dict['element_position'][row,col]\n",
    "            element_dict['imgX']=int(x_pos)\n",
    "            element_dict['imgY']=int(y_pos)\n",
    "\n",
    "            element_dict['angleDeg']=float(recorder_dict['element_theta_contour'][row,col][0])\n",
    "            element_dict['angleDegRand']=float(recorder_dict['element_theta_control'][row,col][0])\n",
    "\n",
    "            element_dict['angleRad']=math.radians(recorder_dict['element_theta_contour'][row,col])\n",
    "\n",
    "\n",
    "            element_dict['contrast']=recorder_dict['gabor_gratingContrast']\n",
    "            element_dict['isTarget']=int(recorder_dict['grid'][row,col])\n",
    "            element_dict['period']=recorder_dict['gabor_lambda']\n",
    "            element_dict['phaseDeg']=recorder_dict['gabor_phase']\n",
    "            element_dict['sigma']=recorder_dict['gabor_stdev']\n",
    "            element_dict['size']=recorder_dict['gabor_imSize']\n",
    "\n",
    "            row_wise_list_elements.append(element_dict)\n",
    "\n",
    "        all_list_elements.append(row_wise_list_elements)\n",
    "\n",
    "\n",
    "    trial_element_dict['elements']=all_list_elements\n",
    "    \n",
    "    return trial_element_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_json_files(test_json,max_totalpoints_per_split=200):\n",
    "    list_contour_params=[]\n",
    "    for trial in test_json['trialData']:\n",
    "        list_contour_params.append(trial['contour_params'])\n",
    "    original_df=pd.DataFrame(list_contour_params)\n",
    "\n",
    "\n",
    "\n",
    "    grouped_df = original_df.groupby(['B', 'A','D','numElements']).size().reset_index(name='counts')\n",
    "\n",
    "\n",
    "    num_points_per_combination=grouped_df.counts[0]\n",
    "    num_combinations=len(grouped_df)\n",
    "    num_totalpoints=len(original_df)\n",
    "    \n",
    "    assert num_totalpoints == num_points_per_combination * num_combinations\n",
    "\n",
    "    ## This has to be computed based on max images in each split\n",
    "    num_splits=int(num_totalpoints/max_totalpoints_per_split)\n",
    "\n",
    "\n",
    "    splits = []\n",
    "    split_indices=[]\n",
    "    df = original_df.copy() \n",
    "    \n",
    "    for i in range(num_splits):\n",
    "        grouped = df.groupby(['B', 'A','D','numElements'])\n",
    "        split = pd.concat([group.sample(n=int(num_points_per_combination/num_splits), random_state=i,replace=False) for _, group in grouped], ignore_index=False)\n",
    "        splits.append(split)\n",
    "        split_indices+=list(split.index)\n",
    "        df = df.drop(split.index)\n",
    "        \n",
    "    assert len(np.unique(split_indices)) == num_totalpoints\n",
    "\n",
    "\n",
    "    list_new_test_json=[]    \n",
    "    for i in range(num_splits):\n",
    "        new_test_json={}\n",
    "        new_test_json['config']=test_json['config']\n",
    "        \n",
    "        t=list(splits[i].index)\n",
    "        np.random.shuffle(t)\n",
    "        \n",
    "        new_test_json['trialData']=[test_json['trialData'][j] for j in t]\n",
    "\n",
    "        list_new_test_json.append(new_test_json)\n",
    "    \n",
    "    return list_new_test_json,grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psychophysics_data(experiment,max_totalpoints_per_split=200):\n",
    "    \n",
    "    '''\n",
    "    This function will make the following:\n",
    "    \n",
    "    1. Images\n",
    "    2. Recorders\n",
    "    3. Big CSV file\n",
    "    4. Big json files\n",
    "    5. Split json files\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    _=make_folders(experiment['experiment_dir'])\n",
    "    ## Save the complete config file for the given experiment\n",
    "    torch.save(experiment,os.path.join(experiment['experiment_dir'],'experiment_config.pth'))\n",
    "    \n",
    "    ## Training, Validation, Psychophysics folders for data\n",
    "    folder_psychophysics_img=make_folders(os.path.join(experiment['experiment_dir'],'psychophysics_img'))\n",
    "\n",
    "    \n",
    "    ## Psychophysics folders for configs - imagerecorders\n",
    "    folder_psychophysics_config = make_folders(os.path.join(experiment['experiment_dir'],'psychophysics_recorder'))\n",
    "\n",
    "    \n",
    "    ## Total number of images for train, val, psychophysics\n",
    "    total_images_psychophysics=len(experiment['beta_list']) * len(experiment['alpha_list']) * len(experiment['num_elements_list']) * len(experiment['D_list']) * experiment['num_images_psychophysics']\n",
    "\n",
    "    \n",
    "    ## CSV File for the training, validation, and the psychophysics code\n",
    "    csv_psychophysics={'img_path':[],'D':[], 'B':[], 'A':[],'numElements':[],'c':[],'img_recorder_path':[],'id_num':[]}\n",
    "    \n",
    "    ## JSON file to use it for behavioral experiments\n",
    "    json_psychophysics={'config':copy.deepcopy(experiment),'trialData':[]}\n",
    "    json_psychophysics['config']['filename']='experiment_config.pth'\n",
    "\n",
    "    \n",
    "    \n",
    "    ###########################################################################################################################################################\n",
    "    # Generating the images for TRAIN\n",
    "    id_num=0\n",
    "    for beta in tqdm(experiment['beta_list']):\n",
    "        for alpha in tqdm(experiment['alpha_list'],disable=True):\n",
    "            for num_elements in tqdm(experiment['num_elements_list'],disable=True):\n",
    "                for D in tqdm(experiment['D_list'],disable=True):\n",
    "                    \n",
    "                    \n",
    "                    for i in range(experiment['num_images_psychophysics']):\n",
    "                        img_id=str(id_num).zfill(len(str(total_images_psychophysics)))\n",
    "\n",
    "                        img_contour, img_control, img_contour_background, img_control_background, points, centers, grid, image_recorder_dict= generate_everything(imWidth=experiment['imWidth'], imHeight=experiment['imHeight'],\n",
    "                                                                                                                                                                  numElements=num_elements,D=D, jitterD=experiment['jitterD'], B=beta, jitterB=experiment['jitterB'], \n",
    "                                                                                                                                                                  startRadius=experiment['startRadius'], alpha_offset=90-alpha,gridSize=experiment['gridSize'],\n",
    "                                                                                                                                                                  max_attempts=100,\n",
    "                                                                                                                                                                  gabor_lambda=experiment['gabor_lambda'],gabor_phase=experiment['gabor_phase'],gabor_stddev=experiment['gabor_stddev'],gabor_imSize=experiment['gabor_imSize'],gabor_elCentre=experiment['gabor_elCentre'],gabor_gratingContrast=experiment['gabor_gratingContrast'])\n",
    "\n",
    "                        # recorder path            \n",
    "                        image_recorder_path= os.path.join(folder_psychophysics_config,'psychophysics_recorder_id' + img_id + '.pth')\n",
    "                        torch.save(image_recorder_dict,image_recorder_path)\n",
    "\n",
    "                        # recorder dictionary for contour_bg1\n",
    "                        img_contour_background_name = 'psychophysics_D' + str(D) + '_B' + str(beta) + '_A' + str(alpha) + '_Numel' + str(num_elements) + '_contour_id' + img_id + '.png'\n",
    "                        img_contour_background_path=os.path.join(folder_psychophysics_img,img_contour_background_name)\n",
    "                        csv_psychophysics=append_values_dict(csv_psychophysics,{'D':D,'B':beta,'A':alpha,'numElements':num_elements,'c':'contour','img_path':img_contour_background_path,'img_recorder_path':image_recorder_path,'id_num':img_id})\n",
    "                        img_contour_background.save(img_contour_background_path)\n",
    "\n",
    "                        # recorder dictionary for nocontour_bg1\n",
    "                        img_control_background_name = 'psychophysics_D' + str(D) + '_B' + str(beta) + '_A' + str(alpha) + '_Numel' + str(num_elements) + '_control_id' + img_id+ '.png'\n",
    "                        img_control_background_path=os.path.join(folder_psychophysics_img,img_control_background_name)\n",
    "                        csv_psychophysics=append_values_dict(csv_psychophysics,{'D':D,'B':beta,'A':alpha,'numElements':num_elements,'c':'control','img_path':img_control_background_path,'img_recorder_path':image_recorder_path,'id_num':img_id})\n",
    "                        img_control_background.save(img_control_background_path)\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        json_psychophysics['trialData'].append(convert_recorder_json(image_recorder_dict,filename=os.path.join('psychophysics_recorder','psychophysics_recorder_id' + img_id + '.pth')))\n",
    "                        \n",
    "                        id_num+=1\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "\n",
    "    print('Completed generating stimuli: psychophysics \\t with id num:',id_num)\n",
    "    ###########################################################################################################################################################\n",
    "    \n",
    "    \n",
    "    ## Save the csv file\n",
    "    pd.DataFrame(csv_psychophysics).to_csv(os.path.join(experiment['experiment_dir'],'psychophysics.csv'),index=False)\n",
    "    \n",
    "    ## Save the json file\n",
    "    with open(os.path.join(experiment['experiment_dir'],'experiment_json.json'), 'w') as json_file:\n",
    "        json.dump(json_psychophysics, json_file)\n",
    "    \n",
    "    ## Get stratified splits for json file and save it\n",
    "    folder_json_splits=make_folders(os.path.join(experiment['experiment_dir'],'json_splits'))\n",
    "    list_new_test_json,grouped_df=get_split_json_files(json_psychophysics,max_totalpoints_per_split)\n",
    "    \n",
    "    for i in range(len(list_new_test_json)):\n",
    "        with open(os.path.join(experiment['experiment_dir'],'json_splits','experiment_json_split_'+str(i).zfill((len(str(len(list_new_test_json))))+1)+'.json'), 'w') as json_file:\n",
    "            json.dump(list_new_test_json[i], json_file)\n",
    "    grouped_df.to_csv(os.path.join(experiment['experiment_dir'],'json_splits','factor_combination.csv'),index=False)\n",
    "    \n",
    "    print('Completed saving stimuli: psychophysics \\t with id num:',id_num)\n",
    "    \n",
    "    return pd.DataFrame(csv_psychophysics),_\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating model-training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _,_=training_data(model_training_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating model-psychophysics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _,_=psychophysics_data(psychophysics_experiment1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
